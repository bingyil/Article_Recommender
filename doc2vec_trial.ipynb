{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from doc2vec import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gloves = load_glove('glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_articles(articles_dirname, gloves):\n",
    "    \"\"\"\n",
    "    Load all .txt files under articles_dirname and return a table (list of lists/tuples)\n",
    "    where each record is a list of:\n",
    "      [filename, title, article-text-minus-title, wordvec-centroid-for-article-text]\n",
    "    We use gloves parameter to compute the word vectors and centroid.\n",
    "    The filename is stripped of the prefix of the articles_dirname pulled in as\n",
    "    script parameter sys.argv[2]. E.g., filename will be \"business/223.txt\"\n",
    "    \"\"\"\n",
    "    flist = filelist(articles_dirname)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flist = filelist('bbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  4.65600000e-02,   2.13180000e-01,  -7.43640000e-03,\n",
       "        -4.58540000e-01,  -3.56390000e-02,   2.36430000e-01,\n",
       "        -2.88360000e-01,   2.15210000e-01,  -1.34860000e-01,\n",
       "        -1.64130000e+00,  -2.60910000e-01,   3.24340000e-02,\n",
       "         5.66210000e-02,  -4.32960000e-02,  -2.16720000e-02,\n",
       "         2.24760000e-01,  -7.51290000e-02,  -6.70180000e-02,\n",
       "        -1.42470000e-01,   3.88250000e-02,  -1.89510000e-01,\n",
       "         2.99770000e-01,   3.93050000e-01,   1.78870000e-01,\n",
       "        -1.73430000e-01,  -2.11780000e-01,   2.36170000e-01,\n",
       "        -6.36810000e-02,  -4.23180000e-01,  -1.16610000e-01,\n",
       "         9.37540000e-02,   1.72960000e-01,  -3.30730000e-01,\n",
       "         4.91120000e-01,  -6.89950000e-01,  -9.24620000e-02,\n",
       "         2.47420000e-01,  -1.79910000e-01,   9.79080000e-02,\n",
       "         8.31180000e-02,   1.52990000e-01,  -2.72760000e-01,\n",
       "        -3.89340000e-02,   5.44530000e-01,   5.37370000e-01,\n",
       "         2.91050000e-01,  -7.35140000e-03,   4.78800000e-02,\n",
       "        -4.07600000e-01,  -2.67590000e-02,   1.79190000e-01,\n",
       "         1.09770000e-02,  -1.09630000e-01,  -2.63950000e-01,\n",
       "         7.39900000e-02,   2.62360000e-01,  -1.50800000e-01,\n",
       "         3.46230000e-01,   2.57580000e-01,   1.19710000e-01,\n",
       "        -3.71350000e-02,  -7.15930000e-02,   4.38980000e-01,\n",
       "        -4.07640000e-02,   1.64250000e-02,  -4.46400000e-01,\n",
       "         1.71970000e-01,   4.62460000e-02,   5.86390000e-02,\n",
       "         4.14990000e-02,   5.39480000e-01,   5.24950000e-01,\n",
       "         1.13610000e-01,  -4.83150000e-02,  -3.63850000e-01,\n",
       "         1.87040000e-01,   9.27610000e-02,  -1.11290000e-01,\n",
       "        -4.20850000e-01,   1.39920000e-01,  -3.93380000e-01,\n",
       "        -6.79450000e-02,   1.21880000e-01,   1.67070000e-01,\n",
       "         7.51690000e-02,  -1.55290000e-02,  -1.94990000e-01,\n",
       "         1.96380000e-01,   5.31940000e-02,   2.51700000e-01,\n",
       "        -3.48450000e-01,  -1.06380000e-01,  -3.46920000e-01,\n",
       "        -1.90240000e-01,  -2.00400000e-01,   1.21540000e-01,\n",
       "        -2.92080000e-01,   2.33530000e-02,  -1.16180000e-01,\n",
       "        -3.57680000e-01,   6.23040000e-02,   3.58840000e-01,\n",
       "         2.90600000e-02,   7.30050000e-03,   4.94820000e-03,\n",
       "        -1.50480000e-01,  -1.23130000e-01,   1.93370000e-01,\n",
       "         1.21730000e-01,   4.45030000e-01,   2.51470000e-01,\n",
       "         1.07810000e-01,  -1.77160000e-01,   3.86910000e-02,\n",
       "         8.15300000e-02,   1.46670000e-01,   6.36660000e-02,\n",
       "         6.13320000e-02,  -7.55690000e-02,  -3.77240000e-01,\n",
       "         1.58500000e-02,  -3.03420000e-01,   2.83740000e-01,\n",
       "        -4.20130000e-02,  -4.07150000e-02,  -1.52690000e-01,\n",
       "         7.49800000e-02,   1.55770000e-01,   1.04330000e-01,\n",
       "         3.13930000e-01,   1.93090000e-01,   1.94290000e-01,\n",
       "         1.51850000e-01,  -1.01920000e-01,  -1.87850000e-02,\n",
       "         2.07910000e-01,   1.33660000e-01,   1.90380000e-01,\n",
       "        -2.55580000e-01,   3.04000000e-01,  -1.89600000e-02,\n",
       "         2.01470000e-01,  -4.21100000e-01,  -7.51560000e-03,\n",
       "        -2.79770000e-01,  -1.93140000e-01,   4.62040000e-02,\n",
       "         1.99710000e-01,  -3.02070000e-01,   2.57350000e-01,\n",
       "         6.81070000e-01,  -1.94090000e-01,   2.39840000e-01,\n",
       "         2.24930000e-01,   6.52240000e-01,  -1.35610000e-01,\n",
       "        -1.73830000e-01,  -4.82090000e-02,  -1.18600000e-01,\n",
       "         2.15880000e-03,  -1.95250000e-02,   1.19480000e-01,\n",
       "         1.93460000e-01,  -4.08200000e-01,  -8.29660000e-02,\n",
       "         1.66260000e-01,  -1.06010000e-01,   3.58610000e-01,\n",
       "         1.69220000e-01,   7.25900000e-02,  -2.48030000e-01,\n",
       "        -1.00240000e-01,  -5.24910000e-01,  -1.77450000e-01,\n",
       "        -3.66470000e-01,   2.61800000e-01,  -1.20770000e-02,\n",
       "         8.31900000e-02,  -2.15280000e-01,   4.10450000e-01,\n",
       "         2.91360000e-01,   3.08690000e-01,   7.88640000e-02,\n",
       "         3.22070000e-01,  -4.10230000e-02,  -1.09700000e-01,\n",
       "        -9.20410000e-02,  -1.23390000e-01,  -1.64160000e-01,\n",
       "         3.53820000e-01,  -8.27740000e-02,   3.31710000e-01,\n",
       "        -2.47380000e-01,  -4.89280000e-02,   1.57460000e-01,\n",
       "         1.89880000e-01,  -2.66420000e-02,   6.33150000e-02,\n",
       "        -1.06730000e-02,   3.40890000e-01,   1.41060000e+00,\n",
       "         1.34170000e-01,   2.81910000e-01,  -2.59400000e-01,\n",
       "         5.52670000e-02,  -5.24250000e-02,  -2.57890000e-01,\n",
       "         1.91270000e-02,  -2.20840000e-02,   3.21130000e-01,\n",
       "         6.88180000e-02,   5.12070000e-01,   1.64780000e-01,\n",
       "        -2.01940000e-01,   2.92320000e-01,   9.85750000e-02,\n",
       "         1.31450000e-02,  -1.06520000e-01,   1.35100000e-01,\n",
       "        -4.53320000e-02,   2.06970000e-01,  -4.84250000e-01,\n",
       "        -4.47060000e-01,   3.33050000e-03,   2.92640000e-03,\n",
       "        -1.09750000e-01,  -2.33250000e-01,   2.24420000e-01,\n",
       "        -1.05030000e-01,   1.23390000e-01,   1.09780000e-01,\n",
       "         4.89940000e-02,  -2.51570000e-01,   4.03190000e-01,\n",
       "         3.53180000e-01,   1.86510000e-01,  -2.36220000e-02,\n",
       "        -1.27340000e-01,   1.14750000e-01,   2.73590000e-01,\n",
       "        -2.18660000e-01,   1.57940000e-02,   8.17540000e-01,\n",
       "        -2.37920000e-02,  -8.54690000e-01,  -1.62030000e-01,\n",
       "         1.80760000e-01,   2.80140000e-02,  -1.43400000e-01,\n",
       "         1.31390000e-03,  -9.17350000e-02,  -8.97040000e-02,\n",
       "         1.11050000e-01,  -1.67030000e-01,   6.83770000e-02,\n",
       "        -8.73880000e-02,  -3.97890000e-02,   1.41840000e-02,\n",
       "         2.11870000e-01,   2.85790000e-01,  -2.87970000e-01,\n",
       "        -5.89960000e-02,  -3.24360000e-02,  -4.70090000e-03,\n",
       "        -1.70520000e-01,  -3.47410000e-02,  -1.14890000e-01,\n",
       "         7.50930000e-02,   9.95260000e-02,   4.81830000e-02,\n",
       "        -7.37750000e-02,  -4.18170000e-01,   4.12680000e-03,\n",
       "         4.44140000e-01,  -1.60620000e-01,   1.42940000e-01,\n",
       "        -2.26280000e+00,  -2.73470000e-02,   8.13110000e-01,\n",
       "         7.74170000e-01,  -2.56390000e-01,  -1.15760000e-01,\n",
       "        -1.19820000e-01,  -2.13630000e-01,   2.84290000e-02,\n",
       "         2.72610000e-01,   3.10260000e-02,   9.67820000e-02,\n",
       "         6.77690000e-03,   1.40820000e-01,  -1.30640000e-02,\n",
       "        -2.96860000e-01,  -7.99130000e-02,   1.95000000e-01,\n",
       "         3.15490000e-02,   2.85060000e-01,  -8.74610000e-02,\n",
       "         9.06110000e-03,  -2.09890000e-01,   5.39130000e-02])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gloves['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ENGLISH_STOP_WORDS = frozenset([\n",
    "    \"a\", \"about\", \"above\", \"across\", \"after\", \"afterwards\", \"again\", \"against\",\n",
    "    \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\",\n",
    "    \"am\", \"among\", \"amongst\", \"amoungst\", \"amount\", \"an\", \"and\", \"another\",\n",
    "    \"any\", \"anyhow\", \"anyone\", \"anything\", \"anyway\", \"anywhere\", \"are\",\n",
    "    \"around\", \"as\", \"at\", \"back\", \"be\", \"became\", \"because\", \"become\",\n",
    "    \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"behind\", \"being\",\n",
    "    \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"bill\", \"both\",\n",
    "    \"bottom\", \"but\", \"by\", \"call\", \"can\", \"cannot\", \"cant\", \"co\", \"con\",\n",
    "    \"could\", \"couldnt\", \"cry\", \"de\", \"describe\", \"detail\", \"do\", \"done\",\n",
    "    \"down\", \"due\", \"during\", \"each\", \"eg\", \"eight\", \"either\", \"eleven\", \"else\",\n",
    "    \"elsewhere\", \"empty\", \"enough\", \"etc\", \"even\", \"ever\", \"every\", \"everyone\",\n",
    "    \"everything\", \"everywhere\", \"except\", \"few\", \"fifteen\", \"fifty\", \"fill\",\n",
    "    \"find\", \"fire\", \"first\", \"five\", \"for\", \"former\", \"formerly\", \"forty\",\n",
    "    \"found\", \"four\", \"from\", \"front\", \"full\", \"further\", \"get\", \"give\", \"go\",\n",
    "    \"had\", \"has\", \"hasnt\", \"have\", \"he\", \"hence\", \"her\", \"here\", \"hereafter\",\n",
    "    \"hereby\", \"herein\", \"hereupon\", \"hers\", \"herself\", \"him\", \"himself\", \"his\",\n",
    "    \"how\", \"however\", \"hundred\", \"i\", \"ie\", \"if\", \"in\", \"inc\", \"indeed\",\n",
    "    \"interest\", \"into\", \"is\", \"it\", \"its\", \"itself\", \"keep\", \"last\", \"latter\",\n",
    "    \"latterly\", \"least\", \"less\", \"ltd\", \"made\", \"many\", \"may\", \"me\",\n",
    "    \"meanwhile\", \"might\", \"mill\", \"mine\", \"more\", \"moreover\", \"most\", \"mostly\",\n",
    "    \"move\", \"much\", \"must\", \"my\", \"myself\", \"name\", \"namely\", \"neither\",\n",
    "    \"never\", \"nevertheless\", \"next\", \"nine\", \"no\", \"nobody\", \"none\", \"noone\",\n",
    "    \"nor\", \"not\", \"nothing\", \"now\", \"nowhere\", \"of\", \"off\", \"often\", \"on\",\n",
    "    \"once\", \"one\", \"only\", \"onto\", \"or\", \"other\", \"others\", \"otherwise\", \"our\",\n",
    "    \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"part\", \"per\", \"perhaps\",\n",
    "    \"please\", \"put\", \"rather\", \"re\", \"same\", \"see\", \"seem\", \"seemed\",\n",
    "    \"seeming\", \"seems\", \"serious\", \"several\", \"she\", \"should\", \"show\", \"side\",\n",
    "    \"since\", \"sincere\", \"six\", \"sixty\", \"so\", \"some\", \"somehow\", \"someone\",\n",
    "    \"something\", \"sometime\", \"sometimes\", \"somewhere\", \"still\", \"such\",\n",
    "    \"system\", \"take\", \"ten\", \"than\", \"that\", \"the\", \"their\", \"them\",\n",
    "    \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\",\n",
    "    \"therefore\", \"therein\", \"thereupon\", \"these\", \"they\", \"thick\", \"thin\",\n",
    "    \"third\", \"this\", \"those\", \"though\", \"three\", \"through\", \"throughout\",\n",
    "    \"thru\", \"thus\", \"to\", \"together\", \"too\", \"top\", \"toward\", \"towards\",\n",
    "    \"twelve\", \"twenty\", \"two\", \"un\", \"under\", \"until\", \"up\", \"upon\", \"us\",\n",
    "    \"very\", \"via\", \"was\", \"we\", \"well\", \"were\", \"what\", \"whatever\", \"when\",\n",
    "    \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\",\n",
    "    \"wherein\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whither\",\n",
    "    \"who\", \"whoever\", \"whole\", \"whom\", \"whose\", \"why\", \"will\", \"with\",\n",
    "    \"within\", \"without\", \"would\", \"yet\", \"you\", \"your\", \"yours\", \"yourself\",\n",
    "    \"yourselves\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "def words(text):\n",
    "    \"\"\"\n",
    "    Given a string, return a list of words normalized as follows.\n",
    "    Split the string to make words first by using regex compile() function\n",
    "    and string.punctuation + '0-9\\\\r\\\\t\\\\n]' to replace all those\n",
    "    char with a space character.\n",
    "    Split on space to get word list.\n",
    "    Ignore words < 3 char long.\n",
    "    Lowercase all words\n",
    "    Remove English stop words\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub('[' + string.punctuation + '0-9\\\\r\\\\t\\\\n]', ' ', text)\n",
    "    text = text.split(\" \")\n",
    "    text = [w for w in text if len(w) > 3]\n",
    "    text = [w for w in text if not w in ENGLISH_STOP_WORDS]\n",
    "    return text\n",
    "\n",
    "def doc2vec(text, gloves):\n",
    "    \"\"\"\n",
    "    Return the word vector centroid for the text. Sum the word vectors\n",
    "    for each word and then divide by the number of words. Ignore words\n",
    "    not in gloves.\n",
    "    \"\"\"\n",
    "    wlist = words(text)\n",
    "    sum = np.zeros(shape=(300,))\n",
    "    for word in wlist:\n",
    "        if word in gloves:\n",
    "            sum = sum + gloves[word]\n",
    "    centroid = sum / len(wlist)\n",
    "    return centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "articles = []\n",
    "for file in flist:\n",
    "    text = get_text(file)\n",
    "    lines = text.split('\\n')\n",
    "    title = lines[0]\n",
    "    contents = lines[1:]\n",
    "    contents = \" \".join(contents)\n",
    "    centroid = doc2vec(contents, glove)    \n",
    "    names = file.split('/')\n",
    "    if len(names) == 3:\n",
    "        filename = names[1]+\"/\" + names[2]\n",
    "    articles.append((filename, title, contents, centroid))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(articles[1][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum = np.zeros(shape=(300,))\n",
    "sum = sum + gloves['the']\n",
    "np.array_equal(gloves['the'], sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(gloves['the'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [(1,2), (3,3), (2,4)]\n",
    "b = sorted(a, key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for x in a:\n",
    "    print x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
